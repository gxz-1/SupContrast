nohup: ignoring input
2024-12-22 17:44:20.525529: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-12-22 17:44:20.682833: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2024-12-22 17:44:20.682885: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2024-12-22 17:44:21.325099: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2024-12-22 17:44:21.325208: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2024-12-22 17:44:21.325223: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
sp------------------------------------------------
name:3pro,index:0
name:4pro,index:1
name:Dji,index:2
name:dao,index:3
name:ha,index:4
Class: 3pro, Images in 'a': 6400, Images in 'b': 6400
Class: 4pro, Images in 'a': 8000, Images in 'b': 7840
Class: Dji, Images in 'a': 6400, Images in 'b': 6400
Class: dao, Images in 'a': 1600, Images in 'b': 640
Class: ha, Images in 'a': 1600, Images in 'b': 1600
Train: [1][10/1430]	BT 0.112 (0.670)	DT 0.000 (0.193)	loss 9.855 (10.050)
Train: [1][20/1430]	BT 0.118 (0.392)	DT 0.000 (0.097)	loss 9.847 (9.950)
Train: [1][30/1430]	BT 0.111 (0.299)	DT 0.000 (0.065)	loss 9.844 (9.908)
Train: [1][40/1430]	BT 0.110 (0.252)	DT 0.000 (0.048)	loss 9.833 (9.885)
Train: [1][50/1430]	BT 0.112 (0.224)	DT 0.000 (0.039)	loss 9.819 (9.872)
Train: [1][60/1430]	BT 0.112 (0.206)	DT 0.000 (0.032)	loss 9.806 (9.861)
Train: [1][70/1430]	BT 0.111 (0.193)	DT 0.000 (0.028)	loss 9.828 (9.855)
Train: [1][80/1430]	BT 0.112 (0.182)	DT 0.000 (0.024)	loss 9.838 (9.850)
Train: [1][90/1430]	BT 0.112 (0.175)	DT 0.000 (0.022)	loss 9.818 (9.846)
Train: [1][100/1430]	BT 0.113 (0.169)	DT 0.000 (0.019)	loss 9.803 (9.843)
Train: [1][110/1430]	BT 0.117 (0.164)	DT 0.000 (0.018)	loss 9.810 (9.840)
Train: [1][120/1430]	BT 0.110 (0.159)	DT 0.000 (0.016)	loss 9.796 (9.838)
Train: [1][130/1430]	BT 0.112 (0.156)	DT 0.000 (0.015)	loss 9.808 (9.835)
Train: [1][140/1430]	BT 0.111 (0.152)	DT 0.000 (0.014)	loss 9.812 (9.834)
Train: [1][150/1430]	BT 0.111 (0.150)	DT 0.000 (0.013)	loss 9.811 (9.833)
Train: [1][160/1430]	BT 0.110 (0.147)	DT 0.000 (0.012)	loss 9.825 (9.831)
Train: [1][170/1430]	BT 0.111 (0.145)	DT 0.000 (0.012)	loss 9.815 (9.831)
Train: [1][180/1430]	BT 0.111 (0.143)	DT 0.000 (0.011)	loss 9.803 (9.829)
Train: [1][190/1430]	BT 0.125 (0.142)	DT 0.000 (0.010)	loss 9.807 (9.829)
Train: [1][200/1430]	BT 0.111 (0.140)	DT 0.000 (0.010)	loss 9.804 (9.828)
Train: [1][210/1430]	BT 0.110 (0.139)	DT 0.000 (0.009)	loss 9.816 (9.827)
Train: [1][220/1430]	BT 0.112 (0.138)	DT 0.000 (0.009)	loss 9.794 (9.827)
Train: [1][230/1430]	BT 0.110 (0.136)	DT 0.000 (0.009)	loss 9.819 (9.826)
Train: [1][240/1430]	BT 0.111 (0.135)	DT 0.000 (0.008)	loss 9.787 (9.826)
Train: [1][250/1430]	BT 0.111 (0.135)	DT 0.000 (0.008)	loss 9.825 (9.825)
Train: [1][260/1430]	BT 0.110 (0.134)	DT 0.000 (0.008)	loss 9.808 (9.825)
Train: [1][270/1430]	BT 0.111 (0.133)	DT 0.000 (0.007)	loss 9.808 (9.824)
Train: [1][280/1430]	BT 0.111 (0.132)	DT 0.000 (0.007)	loss 9.811 (9.824)
Train: [1][290/1430]	BT 0.114 (0.131)	DT 0.000 (0.007)	loss 9.804 (9.824)
Train: [1][300/1430]	BT 0.111 (0.131)	DT 0.000 (0.007)	loss 9.814 (9.823)
Train: [1][310/1430]	BT 0.111 (0.130)	DT 0.000 (0.006)	loss 9.820 (9.823)
Train: [1][320/1430]	BT 0.111 (0.130)	DT 0.000 (0.006)	loss 9.821 (9.823)
Train: [1][330/1430]	BT 0.110 (0.129)	DT 0.000 (0.006)	loss 9.820 (9.823)
Train: [1][340/1430]	BT 0.117 (0.129)	DT 0.000 (0.006)	loss 9.809 (9.822)
Train: [1][350/1430]	BT 0.116 (0.128)	DT 0.000 (0.006)	loss 9.819 (9.822)
Train: [1][360/1430]	BT 0.120 (0.128)	DT 0.000 (0.006)	loss 9.816 (9.822)
Train: [1][370/1430]	BT 0.111 (0.127)	DT 0.000 (0.005)	loss 9.815 (9.821)
Train: [1][380/1430]	BT 0.110 (0.127)	DT 0.000 (0.005)	loss 9.814 (9.821)
Train: [1][390/1430]	BT 0.111 (0.126)	DT 0.000 (0.005)	loss 9.819 (9.821)
Train: [1][400/1430]	BT 0.111 (0.126)	DT 0.000 (0.005)	loss 9.821 (9.821)
Train: [1][410/1430]	BT 0.110 (0.126)	DT 0.000 (0.005)	loss 9.815 (9.821)
Train: [1][420/1430]	BT 0.110 (0.125)	DT 0.000 (0.005)	loss 9.815 (9.820)
Train: [1][430/1430]	BT 0.118 (0.125)	DT 0.000 (0.005)	loss 9.811 (9.820)
Train: [1][440/1430]	BT 0.112 (0.125)	DT 0.000 (0.005)	loss 9.809 (9.820)
Train: [1][450/1430]	BT 0.118 (0.124)	DT 0.000 (0.004)	loss 9.811 (9.820)
Train: [1][460/1430]	BT 0.111 (0.124)	DT 0.000 (0.004)	loss 9.811 (9.820)
Train: [1][470/1430]	BT 0.110 (0.124)	DT 0.000 (0.004)	loss 9.809 (9.820)
Train: [1][480/1430]	BT 0.111 (0.124)	DT 0.000 (0.004)	loss 9.803 (9.820)
Train: [1][490/1430]	BT 0.111 (0.123)	DT 0.000 (0.004)	loss 9.815 (9.819)
Train: [1][500/1430]	BT 0.111 (0.123)	DT 0.000 (0.004)	loss 9.812 (9.819)
Train: [1][510/1430]	BT 0.110 (0.123)	DT 0.000 (0.004)	loss 9.806 (9.819)
Train: [1][520/1430]	BT 0.110 (0.123)	DT 0.000 (0.004)	loss 9.808 (9.819)
Train: [1][530/1430]	BT 0.120 (0.122)	DT 0.000 (0.004)	loss 9.818 (9.819)
Train: [1][540/1430]	BT 0.112 (0.122)	DT 0.000 (0.004)	loss 9.812 (9.819)
Train: [1][550/1430]	BT 0.111 (0.122)	DT 0.000 (0.004)	loss 9.812 (9.818)
Train: [1][560/1430]	BT 0.111 (0.122)	DT 0.000 (0.004)	loss 9.815 (9.818)
Train: [1][570/1430]	BT 0.110 (0.122)	DT 0.000 (0.004)	loss 9.810 (9.818)
